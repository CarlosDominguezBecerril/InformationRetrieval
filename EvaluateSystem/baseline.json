[
    {   
        "model name": "test", 
        "algorithm": "", 
        "trained on": "",
        "metrics": {
            "NDCG@10":{ 
                "msmarco": "",
                "trec-covid": "", 
                "nfcorpus": "", 
                "nq": "", 
                "hotpotqa": "", 
                "fiqa": "", 
                "arguana": "", 
                "webis-touche2020": "", 
                "cqadupstack": "", 
                "quora": "", 
                "dbpedia-entity": "", 
                "scidocs": "", 
                "fever": "", 
                "climate-fever": "", 
                "scifact": ""
            },
            "Recall@100":{ 
                "msmarco": "",
                "trec-covid": "", 
                "nfcorpus": "", 
                "nq": "", 
                "hotpotqa": "", 
                "fiqa": "", 
                "arguana": "", 
                "webis-touche2020": "", 
                "cqadupstack": "", 
                "quora": "", 
                "dbpedia-entity": "", 
                "scidocs": "", 
                "fever": "", 
                "climate-fever": "", 
                "scifact": ""
            }
        }
    },
    {   
        "model name": "Contriever", 
        "algorithm": "moco", 
        "trained on": "cropping(ccnet y wikipedia)",
        "metrics": {
            "NDCG@10":{ 
                "msmarco": 20.6,
                "trec-covid": 27.4, 
                "nfcorpus": 31.7, 
                "nq": 25.4, 
                "hotpotqa": 48.1, 
                "fiqa": 24.5, 
                "arguana": 37.9, 
                "webis-touche2020": 19.3, 
                "cqadupstack": 28.4, 
                "quora": 83.5, 
                "dbpedia-entity": 29.2, 
                "scidocs": 14.9, 
                "fever": 68.2, 
                "climate-fever": 15.5, 
                "scifact": 64.9
            },
            "Recall@100":{ 
                "msmarco": 67.2,
                "trec-covid": 17.2, 
                "nfcorpus": 29.4, 
                "nq": 77.1, 
                "hotpotqa": 70.4, 
                "fiqa": 56.2, 
                "arguana": 90.1, 
                "webis-touche2020": 22.5, 
                "cqadupstack": 61.4, 
                "quora": 98.7, 
                "dbpedia-entity": 45.3, 
                "scidocs": 36, 
                "fever": 93.6, 
                "climate-fever": 44.1, 
                "scifact": 92.6
            }
        }
    },
    {   
        "model name": "Contriever - msmarco", 
        "algorithm": "moco", 
        "trained on": "cropping(ccnet y wikipedia) + superv(ms marco)", 
        "metrics": {
            "NDCG@10":{ 
                "msmarco": 40.7,
                "trec-covid": 59.6, 
                "nfcorpus": 32.8, 
                "nq": 49.8, 
                "hotpotqa": 63.8, 
                "fiqa": 32.9, 
                "arguana": 44.6, 
                "webis-touche2020": 23, 
                "cqadupstack": 34.5, 
                "quora": 86.5, 
                "dbpedia-entity": 41.3, 
                "scidocs": 16.5, 
                "fever": 75.8, 
                "climate-fever": 23.7, 
                "scifact": 67.7
            },
            "Recall@100":{ 
                "msmarco": 89.1,
                "trec-covid": 40.7, 
                "nfcorpus": 30, 
                "nq": 92.5, 
                "hotpotqa": 77.7, 
                "fiqa": 65.6, 
                "arguana": 97.7, 
                "webis-touche2020": 29.4, 
                "cqadupstack": 66.3, 
                "quora": 99.3, 
                "dbpedia-entity": 54.1, 
                "scidocs": 37.8, 
                "fever": 94.9, 
                "climate-fever": 57.4, 
                "scifact": 94.7
            }
        }
    },
    {   
        "model name": "BM25", 
        "trained on": "statistic", 
        "metrics": {
            "NDCG@10":{ 
                "msmarco": 22.8,
                "trec-covid": 65.6, 
                "nfcorpus": 32.5, 
                "nq": 32.9, 
                "hotpotqa": 60.3, 
                "fiqa": 23.6, 
                "arguana": 31.5, 
                "webis-touche2020": 36.7, 
                "cqadupstack": 29.9, 
                "quora": 78.9, 
                "dbpedia-entity": 31.3, 
                "scidocs": 15.8, 
                "fever": 75.3, 
                "climate-fever": 21.3, 
                "scifact": 66.5
            }
        }
    },
    {   
        "model name": "BM25 + CE (RERANKING)", 
        "trained on": "statistic",
        "metrics": {
            "NDCG@10":{ 
                "msmarco": 41.3,
                "trec-covid": 75.7, 
                "nfcorpus": 35, 
                "nq": 53.5, 
                "hotpotqa": 70.7, 
                "fiqa": 34.7, 
                "arguana": 31.1, 
                "webis-touche2020": 27.1, 
                "cqadupstack": 37, 
                "quora": 82.5, 
                "dbpedia-entity": 40.9, 
                "scidocs": 16.6, 
                "fever": 81.9, 
                "climate-fever": 25.3, 
                "scifact": 68.8
            }
        }
    },
    {   
        "model name": "DPR", 
        "trained on": "superv(NQ,TriviaQA,WQ,TREC)",
        "metrics": {
            "NDCG@10":{ 
                "msmarco": 17.7,
                "trec-covid": 33.2, 
                "nfcorpus": 18.9, 
                "nq": 47.4, 
                "hotpotqa": 39.1, 
                "fiqa": 11.2, 
                "arguana": 17.5, 
                "webis-touche2020": 13.1, 
                "cqadupstack": 15.3, 
                "quora": 24.8, 
                "dbpedia-entity": 26.3, 
                "scidocs": 7.7, 
                "fever": 56.2, 
                "climate-fever": 14.8, 
                "scifact": 31.8
            }
        }
    },
    {   
        "model name": "GenQ", 
        "trained on": "superv(ms-marco)",
        "metrics": {
            "NDCG@10":{ 
                "msmarco": 40.8,
                "trec-covid": 61.9, 
                "nfcorpus": 31.9, 
                "nq": 35.8, 
                "hotpotqa": 53.4, 
                "fiqa": 30.8, 
                "arguana": 49.3, 
                "webis-touche2020": 18.2, 
                "cqadupstack": 34.7, 
                "quora": 83, 
                "dbpedia-entity": 32.8, 
                "scidocs": 14.3, 
                "fever": 66.9, 
                "climate-fever": 17.5, 
                "scifact": 64.4
            }
        }
    },
    {   
        "model name": "LaPraDoR", 
        "trained on": "superv(ms-marco)",
        "metrics": {
            "NDCG@10":{ 
                "trec-covid": 48.2, 
                "nfcorpus": 26.7, 
                "nq": 44.3, 
                "hotpotqa": 48.4, 
                "fiqa": 24.5, 
                "arguana": 41.2, 
                "webis-touche2020": 15.6, 
                "cqadupstack": 25, 
                "quora": 84, 
                "dbpedia-entity": 30.3, 
                "scidocs": 12.7, 
                "fever": 66.4, 
                "climate-fever": 20.6, 
                "scifact": 52.9
            }
        }
    },
    {   
        "model name": "Promptagator (zero-shot)", 
        "trained on": "cropping(C4) + unsuperv(NQ)", 
        "metrics": {
            "NDCG@10":{ 
                "trec-covid": 72.7, 
                "nfcorpus": 33.4, 
                "hotpotqa": 60.4, 
                "fiqa": 40.4, 
                "arguana": 53.8, 
                "webis-touche2020": 26.6, 
                "dbpedia-entity": 36.4, 
                "scidocs": 16.3, 
                "fever": 76.2, 
                "climate-fever": 21.4, 
                "scifact": 62.3
            }
        }
    },
    {   
        "model name": "Promptagator (zero-shot) + reranker", 
        "trained on": "cropping(C4) + unsuperv(NQ)",
        "metrics": {
            "NDCG@10":{ 
                "trec-covid": 76, 
                "nfcorpus": 36, 
                "hotpotqa": 71.2, 
                "fiqa": 45.9, 
                "arguana": 52.1, 
                "webis-touche2020": 27.8, 
                "dbpedia-entity": 41.3, 
                "scidocs": 19.9, 
                "fever": 83.8, 
                "climate-fever": 22.6, 
                "scifact": 73.2
            }
        }
    },
    {   
        "model name": "AligneR_xxl (zero-shot)", 
        "trained on": "superv(ms-marco)",
        "metrics": {
            "NDCG@10":{ 
                "trec-covid": 75.9, 
                "nfcorpus": 35.2, 
                "nq": 60.5,
                "hotpotqa": 65.2, 
                "fiqa": 43.5, 
                "arguana": 33.8, 
                "webis-touche2020": 34.5, 
                "quora": 86, 
                "dbpedia-entity": 45, 
                "fever": 74.2, 
                "climate-fever": 19.7, 
                "scifact": 73.1
            }
        }
    }
]